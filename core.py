import torch
import openai
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration

import warnings
warnings.filterwarnings("ignore")

class generate_caption():
    def __init__(self):
        self.captioning_model_name = "Salesforce/blip-image-captioning-base"
        self.model_id = "gpt-3.5-turbo"

    def generate_vanilla_caption(self, raw_image):
        processor = BlipProcessor.from_pretrained(self.captioning_model_name)
        if torch.cuda.is_available():
            model = BlipForConditionalGeneration.from_pretrained(self.captioning_model_name).to("cuda")
        else:
            model = BlipForConditionalGeneration.from_pretrained(self.captioning_model_name)

        if torch.cuda.is_available():
            inputs = processor(raw_image, return_tensors="pt").to("cuda")
        else:
            inputs = processor(raw_image, return_tensors="pt")

        out = model.generate(**inputs)
        return processor.decode(out[0], skip_special_tokens=True)


    def generate_filtered_captions(self, caption, N=5):
        prompt = """The below text was generated by an image captioning AI. Make it better. Return {} versions of the output seperated by '##' in one line. Do not print additional information. The text :{}.""".format(N, caption)
        res_json = openai.ChatCompletion.create(
        model=self.model_id,
        messages=[
                {"role": "system", "content": prompt},
            ]
        )
        res = res_json['choices'][0]['message']['content']
        res_list = res.split('##')
        return res_list

    def run(self, img, N):
        if isinstance(img, str):
            raw_image = Image.open(IMG_PATH).convert('RGB')
        else:
            raw_image = img
        caption = self.generate_vanilla_caption(raw_image)
        filtered_caption = self.generate_filtered_captions(caption, N)
        return filtered_caption


if __name__=='__main__':    
    IMG_PATH = "data\Image2.png"
    print(generate_caption().run(IMG_PATH, 6))

    